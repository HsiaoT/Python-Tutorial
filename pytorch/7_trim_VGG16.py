# -*- coding: utf-8 -*-
# refer to https://rowantseng.medium.com/%E4%BD%BF%E7%94%A8-pytorch-%E6%8F%90%E4%BE%9B%E7%9A%84%E9%A0%90%E8%A8%93%E7%B7%B4%E6%A8%A1%E5%9E%8B-pretrained-model-%E5%81%9A%E7%89%A9%E4%BB%B6%E5%81%B5%E6%B8%AC-object-detection-57ad9772a982

"""
pytorch.ipynb

Automatically generated by Colaboratory.

"""

# refer to https://www.mdeditor.tw/pl/pVEw/zh-tw
# nn.Sequential
import torch
import torchvision

image = torch.zeros((1,3,800,800)).float()

# trim VGG16 based on the final output size.
# scenario: 
# input 3*800*800
# sub_sampling 16
# we want the output features better than 800//16
# =======================
model = torchvision.models.vgg16(pretrained=True)
model_list = list(model.features)    # len(model_list)=31
# for layer in model_list:
#   print(layer)

trim_model = []
image_clone = image.clone()

for layer in model_list:
  image_clone = layer(image_clone)
  if image_clone.size()[2] < 800//16:
      break
  trim_model.append(layer)
  out_channels = image_clone.size()[1]
# print(image_clone.size()) # [1, 512, 25, 25]
# print(len(trim_model))    # 30
# print(out_channels)       # 512
faster_rcnn_feature_extractor = nn.Sequential(*req_features)

out_image = faster_rcnn_feature_extractor(image)
print(out_image.shape)      # [1, 512, 50, 50]

